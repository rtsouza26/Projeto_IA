{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Projeto_IA .ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUYiLuy_KfJ",
        "colab_type": "text"
      },
      "source": [
        "Projeto de predição de grau de estado deterioração do figado devido ao HCV\n",
        "\n",
        "Equipe: Daniel Lemos,\n",
        "        Rafael Targino\n",
        "        \n",
        "Data_Set: https://archive.ics.uci.edu/ml/machine-learning-databases/00503/HCV-Egy-Data.zip\n",
        "\n",
        "\n",
        "Passos:\n",
        "Ler os dados e normalizá-los cross-validation 10 folds\n",
        "Utilizar os seguintes algoritimos:\n",
        "1- KNN variando o K(1,3,5,10)\n",
        "2- Naive-Bayes\n",
        "3- Arvore de Decisão (Random Forrest) variando o numero de florestas\n",
        "4- RLScore(variando o numero de kernels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKKUBivC_KfP",
        "colab_type": "code",
        "outputId": "c0efad26-49d6-4e1d-c5dd-cd293af36cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install rlscore\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import preprocessing\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pl\n",
        "%matplotlib inline"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rlscore in /usr/local/lib/python3.6/dist-packages (0.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFLWhXJIMtm0",
        "colab_type": "text"
      },
      "source": [
        "Base de dados de pacientes egípcios que foram submetidos a doses de tratamento para HCV cerca de 18 meses. A discretização deve ser aplicada com base em recomendações de especialistas; há um arquivo anexado mostra como.\n",
        "\n",
        "A base de dados reúne cerca de \n",
        "\n",
        "Os dados apresentão o estágio inicial da entrada dos pacientes e as taxas , o problema é diagnosticar o grau de degradação do fígado através dos exames previamente levantados, sem a necessidade de exame de ultrasom ou histológico, ou seja prever o resultado do exame histológio acelerando assim que tipo de tratamento aplicar.\n",
        "as classes são não fibroso que significa saldável, fibroso, fibroso com poucas cepas do vírus, fibroso com muitas cepas e cirrose.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8SQ07ME9uiL",
        "colab_type": "code",
        "outputId": "d44d2dbf-39c5-4837-d1a6-31879ad5a7f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "df = pd.read_csv(\"https://drive.google.com/uc?authuser=0&id=1S2HnHU5zoI7ERYhVd8naSaUMt0eJZW3L&export=download\")\n",
        "\n",
        "columns = df.columns\n",
        "\n",
        "\n",
        "ax = df['Baselinehistological staging'].value_counts().plot.bar()\n",
        "print(ax)\n",
        "classes = df['Baselinehistological staging'].unique()\n",
        "\n",
        "index_amostra= list()\n",
        "index_1 = 0\n",
        "index_3 = 0\n",
        "index_4 = 0\n",
        "index_2 = 0\n",
        "for x in df.index:\n",
        "  if index_2<332:\n",
        "    if df.loc[x,'Baselinehistological staging'] == 2:\n",
        "      index_amostra.append(x)\n",
        "      index_2= index_2+1\n",
        "  if index_4<332:    \n",
        "    if df.loc[x,'Baselinehistological staging'] == 4:\n",
        "      index_amostra.append(x)\n",
        "      index_4 = index_4 +1\n",
        "  if index_3<332:\n",
        "    if df.loc[x,'Baselinehistological staging'] == 3:\n",
        "      index_amostra.append(x)\n",
        "      index_3 = index_3 +1\n",
        "  if index_1<332:\n",
        "    if df.loc[x,'Baselinehistological staging'] ==1:\n",
        "      index_amostra.append(x)\n",
        "      index_1 = index_1 +1\n",
        "dfAvalues = []\n",
        "for g in index_amostra:\n",
        "  dfAvalues.append(df.iloc[g].values)\n",
        "\n",
        "dfAmostra = pd.DataFrame(dfAvalues,columns=columns)\n",
        "print(dfAmostra)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AxesSubplot(0.125,0.125;0.775x0.755)\n",
            "      Age   Gender  ...  Baseline histological Grading  Baselinehistological staging\n",
            "0     56.0     1.0  ...                           13.0                           2.0\n",
            "1     46.0     1.0  ...                            4.0                           2.0\n",
            "2     57.0     1.0  ...                            4.0                           4.0\n",
            "3     49.0     2.0  ...                           10.0                           3.0\n",
            "4     59.0     1.0  ...                           11.0                           1.0\n",
            "...    ...     ...  ...                            ...                           ...\n",
            "1323  59.0     1.0  ...                           16.0                           2.0\n",
            "1324  46.0     1.0  ...                           11.0                           2.0\n",
            "1325  52.0     2.0  ...                           16.0                           2.0\n",
            "1326  55.0     1.0  ...                           10.0                           2.0\n",
            "1327  42.0     1.0  ...                            6.0                           2.0\n",
            "\n",
            "[1328 rows x 29 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD1CAYAAACrz7WZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ4a7JHXIcJekDhnuktQhw12SOvR/A4b84XVaTGQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-5pjiqxu0t0",
        "colab_type": "text"
      },
      "source": [
        "Preparação dos dados de três formas diferentes, sendo escalados entre 0 e 1, valores absolutos  e normalizados, gerando três dataframes diferentes para os testes, separação das labels do Features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPQzqa5Mobvv",
        "colab_type": "code",
        "outputId": "1442fbcc-638b-4f4c-e725-3b2360f78e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "from sklearn import preprocessing\n",
        "dfclass = pd.Series(dfAmostra['Baselinehistological staging'])\n",
        "dfsclass = pd.DataFrame(dfAmostra.iloc[:,0:28]) \n",
        "\n",
        "columns = dfsclass.columns\n",
        "ax = dfclass.value_counts().plot.bar()\n",
        "print(ax)\n",
        "\n",
        "repcolumns = list()\n",
        "for index, column in enumerate(columns):\n",
        "  column = column.replace(\" \",\"\")\n",
        "  repcolumns.append(column)\n",
        "x = dfsclass.values\n",
        "x_scale = preprocessing.scale(dfsclass)\n",
        "x_normal = preprocessing.normalize(dfsclass, norm='l1')\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(dfsclass)\n",
        "x_abs = max_abs_scaler.fit_transform(dfsclass)\n",
        "\n",
        "\n",
        "dfnorm = pd.DataFrame(x_normal, columns = repcolumns)\n",
        "df_abs = pd.DataFrame(x_abs, columns = repcolumns)\n",
        "df_scale = pd.DataFrame(x_scaled, columns = repcolumns)\n",
        "\n",
        "dfL = {'Normalizado': dfnorm,'Valor_Absoluto': df_abs,'Escalado': df_scale}\n",
        "\n",
        "\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD+CAYAAADBCEVaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWqQ4S5JDfp/G8hAN55bL7gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03SRRxzrukAg",
        "colab_type": "text"
      },
      "source": [
        "Geração dos kfolds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0kO2Se46R18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def TesteNB(dfL,dl,skf):\n",
        "  from sklearn.model_selection import cross_val_score\n",
        "  import numpy\n",
        "  Result_cross_valG =[]\n",
        "  Result_cross_valM =[]\n",
        "  Result_AcG = []\n",
        "  Result_AcM = []\n",
        "  for Features, Labels in skf.split(dfL[dl],dfclass):\n",
        "    X_train, X_test = dfL[dl].iloc[Features], dfL[dl].iloc[Labels]\n",
        "    y_train, y_test = dfclass.iloc[Features], dfclass.iloc[Labels]\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "    y_predG = gnb.predict(X_test)\n",
        "    acuG = metrics.accuracy_score(y_test, y_predG)\n",
        "    Result_cross_valG.append(max(cross_val_score(gnb,dfL[dl],dfclass,cv=10)))\n",
        "    \n",
        "    if Result_AcG != []:\n",
        "      if max(Result_AcG)<acuG:\n",
        "        Result_AcG.append(acuG)\n",
        "    else:\n",
        "      Result_AcG.append(acuG)\n",
        "\n",
        "    gnm = MultinomialNB()\n",
        "    gnm.fit(X_train, y_train)\n",
        "    y_predM = gnb.predict(X_test)\n",
        "    acuM = metrics.accuracy_score(y_test,y_predM)\n",
        "    Result_cross_valM.append(max(cross_val_score(gnm,dfL[dl],dfclass,cv=10)))\n",
        "    if Result_AcM != []:\n",
        "      if max(Result_AcM)<acuM:\n",
        "        Result_AcM.append(acuM)\n",
        "    else:\n",
        "      Result_AcM.append(acuM)\n",
        "\n",
        "  Result_cross_in_NBG = max(Result_cross_valG)\n",
        "  Result_cross_in_NBM = max(Result_cross_valM)\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "  return [Result_cross_in_NBG,Result_cross_in_NBM]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBhv4DiMqxC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rlscore.learner import LeaveOneOutRLS\n",
        "from rlscore.measure import ova_accuracy\n",
        "from rlscore.utilities.multiclass import to_one_vs_all\n",
        "def Testerls(dfL, dl, skf):\n",
        "  Result_Acu=[]\n",
        "  Result_cross_RLS=[]\n",
        "  for Features, Labels in skf.split(dfL[dl],dfclass):\n",
        "    X_train, X_test = dfL[dl].iloc[Features], dfL[dl].iloc[Labels]\n",
        "    y_train, y_test = dfclass.iloc[Features], dfclass.iloc[Labels]\n",
        "    y_train = to_one_vs_all(y_train, False)\n",
        "    y_test = to_one_vs_all(y_test, False)\n",
        "    regparams = [2.**i for i in range(-15, 16)]\n",
        "    learner = LeaveOneOutRLS(X_train, y_train, regparams=regparams, measure=ova_accuracy)\n",
        "    P_test = learner.predict(X_test)\n",
        "    acu = ova_accuracy(y_test, P_test)\n",
        "    \n",
        "    if Result_Acu != []:\n",
        "      if max(Result_Acu)<acu:\n",
        "        Result_Acu.append(acu)\n",
        "    else:\n",
        "      Result_Acu.append(acu)\n",
        "  return max(Result_Acu)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQnbtzKStbp_",
        "colab_type": "code",
        "outputId": "4b19e54e-32b0-4c8d-a447-5c58cd053ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "#from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from rlscore.learner import LeaveOneOutRLS\n",
        "from rlscore.measure import ova_accuracy\n",
        "from rlscore.utilities.multiclass import to_one_vs_all\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10,shuffle=True)\n",
        "Resultado_NB={}\n",
        "Resultado_Rls={}\n",
        "Resultado_Rf = {}\n",
        "X_index = dfnorm.index\n",
        "Y_index = dfclass.index\n",
        "estimators =[100,200,500,800]\n",
        "neighbors = [1,3,5,10]\n",
        "\n",
        "\n",
        "\n",
        "for dl in dfL:\n",
        "  Resultado_NB[dl] = TesteNB(dfL,dl,skf)\n",
        "  Resultado_Rls[dl] =Testerls(dfL,dl,skf)\n",
        "  #Resultado_Rf[dl] = TesteRF(dfL,dl,skf)\n",
        "print(Resultado_NB)\n",
        "print(Resultado_Rls)  \n",
        "\n",
        "Resul_NB = pd.DataFrame(Resultado_NB.values(),columns=['Gaussiano','Multinomial'],index=['Normalizado','Valor_Absoluto','Escalado'])\n",
        "Resul_NB.to_csv('AcuNB.csv',sep='\\t', encoding='utf-8')\n",
        "Resul_Rls = pd.DataFrame(Resultado_Rls.values(),index=['Normalizado', 'Valor_Absoluto','Escalado'],columns=['Acuracia'])\n",
        "\n",
        "print(Resul_NB.plot.bar())\n",
        "print(Resul_Rls.plot.bar())\n",
        "\n",
        "'''for dl in dfL:\n",
        "  \n",
        "   \n",
        "\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "    y_pred = gnb.predict(X_test)\n",
        "    acu = metrics.accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy GaussianNB: {}'.format(acu))\n",
        "\n",
        "    gnb = MultinomialNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "    y_pred = gnb.predict(X_test)\n",
        "    print('Accuracy MultinominalNB: {}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
        "\n",
        "    for n in estimators:\n",
        "      rf = RandomForestClassifier(n_estimators=n)\n",
        "      rf.fit(X_train,y_train)\n",
        "      predictions = rf.predict(X_test)\n",
        "      print('Accuracy com estimator {} : {}'.format(n,metrics.accuracy_score(y_test, predictions)))\n",
        "\n",
        "\n",
        "    y_train = to_one_vs_all(y_train, False)\n",
        "    y_test = to_one_vs_all(y_test, False)\n",
        "    regparams = [2.**i for i in range(-15, 16)]\n",
        "    learner = LeaveOneOutRLS(X_train, y_train, regparams=regparams, measure=ova_accuracy)\n",
        "    P_test = learner.predict(X_test)\n",
        "      \n",
        "    print(\"test set accuracy {}\".format(ova_accuracy(y_test, P_test)) )\n",
        "\n",
        "    \n",
        "  \n",
        "    y_train = to_one_vs_all(y_train, False)\n",
        "    y_test = to_one_vs_all(y_test, False)\n",
        "    regparams = [2.**i for i in range(-15, 16)]\n",
        "    learner = LeaveOneOutRLS(X_train, y_train, regparams=regparams, measure=ova_accuracy)\n",
        "    P_test = learner.predict(X_test)\n",
        "      \n",
        "    print(\"test set accuracy {}\".format(ova_accuracy(y_test, P_test)) )\n",
        "\n",
        "    for n in neighbors:\n",
        "      \n",
        "      neigh = KNeighborsClassifier(n_neighbors=n)\n",
        "      neigh.fit(X_train, y_train)\n",
        "      y_predic = neigh.predict(X_test,y_test)\n",
        "  '''\n"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'Normalizado': [0.3181818181818182, 0.30303030303030304], 'Valor_Absoluto': [0.3106060606060606, 0.2878787878787879], 'Escalado': [0.3106060606060606, 0.3333333333333333]}\n",
            "{'Normalizado': 0.3484848484848485, 'Valor_Absoluto': 0.2803030303030303, 'Escalado': 0.26515151515151514}\n",
            "AxesSubplot(0.125,0.125;0.775x0.755)\n",
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for dl in dfL:\\n  \\n   \\n\\n    gnb = GaussianNB()\\n    gnb.fit(X_train, y_train)\\n    y_pred = gnb.predict(X_test)\\n    acu = metrics.accuracy_score(y_test, y_pred)\\n    print(\\'Accuracy GaussianNB: {}\\'.format(acu))\\n\\n    gnb = MultinomialNB()\\n    gnb.fit(X_train, y_train)\\n    y_pred = gnb.predict(X_test)\\n    print(\\'Accuracy MultinominalNB: {}\\'.format(metrics.accuracy_score(y_test, y_pred)))\\n\\n    for n in estimators:\\n      rf = RandomForestClassifier(n_estimators=n)\\n      rf.fit(X_train,y_train)\\n      predictions = rf.predict(X_test)\\n      print(\\'Accuracy com estimator {} : {}\\'.format(n,metrics.accuracy_score(y_test, predictions)))\\n\\n\\n    y_train = to_one_vs_all(y_train, False)\\n    y_test = to_one_vs_all(y_test, False)\\n    regparams = [2.**i for i in range(-15, 16)]\\n    learner = LeaveOneOutRLS(X_train, y_train, regparams=regparams, measure=ova_accuracy)\\n    P_test = learner.predict(X_test)\\n      \\n    print(\"test set accuracy {}\".format(ova_accuracy(y_test, P_test)) )\\n\\n    \\n  \\n    y_train = to_one_vs_all(y_train, False)\\n    y_test = to_one_vs_all(y_test, False)\\n    regparams = [2.**i for i in range(-15, 16)]\\n    learner = LeaveOneOutRLS(X_train, y_train, regparams=regparams, measure=ova_accuracy)\\n    P_test = learner.predict(X_test)\\n      \\n    print(\"test set accuracy {}\".format(ova_accuracy(y_test, P_test)) )\\n\\n    for n in neighbors:\\n      \\n      neigh = KNeighborsClassifier(n_neighbors=n)\\n      neigh.fit(X_train, y_train)\\n      y_predic = neigh.predict(X_test,y_test)\\n  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAE9CAYAAAAF/alEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncw56M7Oc+/9B8cCd7AD+mwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAE5CAYAAACebOtSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS9BHRNRcgj4iouYS9BERNZegj4iouf8PnmVcVq7px0EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLu_i0assqzj",
        "colab_type": "code",
        "outputId": "99406b53-7754-42d0-c6e1-9da75a7dd523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def TesteRF(dfL,dl,skf):\n",
        "  \n",
        "  estimators =[100,200,500,800]\n",
        "  Result_Acu = {}\n",
        "  Result_cross_RF ={}\n",
        "  for Features, Labels in skf.split(dfL[dl],dfclass):\n",
        "    X_train, X_test = dfL[dl].iloc[Features], dfL[dl].iloc[Labels]\n",
        "    y_train, y_test = dfclass.iloc[Features], dfclass.iloc[Labels]\n",
        "    for n in estimators:\n",
        "      rf = RandomForestClassifier(n_estimators=n)\n",
        "      rf.fit(X_train,y_train)\n",
        "      predictions = rf.predict(X_test)\n",
        "      acu = metrics.accuracy_score(y_test, predictions)\n",
        "      Result_cross_RF[n]= max(cross_val_score(rf,dfL[dl],dfclass,cv=2))\n",
        "      if n in Result_Acu:\n",
        "        if Result_Acu[n]>acu:\n",
        "            Result_Acu[n]=acu\n",
        "      else:\n",
        "        Result_Acu[n]=acu\n",
        "     \n",
        "  return(Result_Acu,Result_cross_RF)\n",
        "print(TesteRF(dfL,dl,skf))\n",
        "  "
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-cc01ad32d6a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResult_Acu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mResult_cross_RF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTesteRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-131-cc01ad32d6a2>\u001b[0m in \u001b[0;36mTesteRF\u001b[0;34m(dfL, dl, skf)\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0macu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mResult_cross_RF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdfL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdfclass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mResult_Acu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mResult_Acu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0macu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wToYQZE0aewH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E288HjBPsocs",
        "colab_type": "text"
      },
      "source": [
        "Random Forrest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIo5PLfFtuzk",
        "colab_type": "text"
      },
      "source": [
        "KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFxR8gjgtw3X",
        "colab_type": "code",
        "outputId": "3f822825-a010-4cf1-97ec-40aa19ccf80c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "neighbors = [1,3,5,10]\n",
        "\n",
        "for df in dfL:\n",
        "  for n in neighbors:\n",
        "    train_features, test_features, train_labels, test_labels = train_test_split(df, dfclass, test_size = 0.25, random_state = 42)\n",
        "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "    neigh.fit(train_features, train_labels)\n",
        "    y_predic = neigh.predict(test_features)\n",
        "    acc = accuracy_score(test_labels,y_predic)    \n",
        "    print(acc)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.24096385542168675\n",
            "0.24096385542168675\n",
            "0.24096385542168675\n",
            "0.24096385542168675\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}