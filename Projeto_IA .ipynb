{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Projeto_IA .ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUYiLuy_KfJ",
        "colab_type": "text"
      },
      "source": [
        "Projeto de predição de grau de estado deterioração do figado devido ao HCV\n",
        "\n",
        "Equipe: Daniel Lemos,\n",
        "        Rafael Targino\n",
        "        \n",
        "Data_Set: https://archive.ics.uci.edu/ml/machine-learning-databases/00503/HCV-Egy-Data.zip\n",
        "\n",
        "\n",
        "Passos:\n",
        "Ler os dados e normalizá-los cross-validation 10 folds\n",
        "Utilizar os seguintes algoritimos:\n",
        "1- KNN variando o K(1,3,5,10)\n",
        "2- Naive-Bayes\n",
        "3- Arvore de Decisão (Random Forrest) variando o numero de florestas\n",
        "4- RLScore(variando o numero de kernels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKKUBivC_KfP",
        "colab_type": "code",
        "outputId": "7c37986d-84ed-4e61-c2c4-04277e9b76bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!pip install rlscore\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import preprocessing\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pl\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rlscore\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/25/bdf769f00b65602aa9fa7a1c674c6a508c427249e1ee8f2e1e1d7adcadad/rlscore-0.8.1.tar.gz (778kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 2.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: rlscore\n",
            "  Building wheel for rlscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rlscore: filename=rlscore-0.8.1-cp36-cp36m-linux_x86_64.whl size=1824842 sha256=75abc9c1b41dfe7d912d381ceb34e9fca155bda10b0347402d0f6dbeb2c4ab92\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/d7/27/cd7b2182c3f5c012dbbf9a8507116b9c49140ffc733223c07b\n",
            "Successfully built rlscore\n",
            "Installing collected packages: rlscore\n",
            "Successfully installed rlscore-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFLWhXJIMtm0",
        "colab_type": "text"
      },
      "source": [
        "Base de dados de pacientes egípcios que foram submetidos a doses de tratamento para HCV cerca de 18 meses. A discretização deve ser aplicada com base em recomendações de especialistas; há um arquivo anexado mostra como.\n",
        "\n",
        "A base de dados reúne cerca de \n",
        "\n",
        "Os dados apresentão o estágio inicial da entrada dos pacientes e as taxas , o problema é diagnosticar o grau de degradação do fígado através dos exames previamente levantados, sem a necessidade de exame de ultrasom ou histológico, ou seja prever o resultado do exame histológio acelerando assim que tipo de tratamento aplicar.\n",
        "as classes são não fibroso que significa saldável, fibroso, fibroso com poucas cepas do vírus, fibroso com muitas cepas e cirrose.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8SQ07ME9uiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"https://drive.google.com/uc?authuser=0&id=1S2HnHU5zoI7ERYhVd8naSaUMt0eJZW3L&export=download\")\n",
        "columns = df.columns\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-5pjiqxu0t0",
        "colab_type": "text"
      },
      "source": [
        "Preparação dos dados de três formas diferentes, sendo escalados entre 0 e 1, valores absolutos  e normalizados, gerando três dataframes diferentes para os testes, separação das labels do Features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPQzqa5Mobvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "dfclass = pd.Series(df['Baselinehistological staging'])\n",
        "dfsclass = pd.DataFrame(df.iloc[:,0:28]) \n",
        "columns = dfsclass.columns\n",
        "\n",
        "repcolumns = list()\n",
        "for index, column in enumerate(columns):\n",
        "  column = column.replace(\" \",\"\")\n",
        "  repcolumns.append(column)\n",
        "x = dfsclass.values\n",
        "x_scale = preprocessing.scale(dfsclass)\n",
        "x_normal = preprocessing.normalize(dfsclass, norm='l1')\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(dfsclass)\n",
        "x_abs = max_abs_scaler.fit_transform(dfsclass)\n",
        "\n",
        "\n",
        "dfnorm = pd.DataFrame(x_normal, columns = repcolumns)\n",
        "df_abs = pd.DataFrame(x_abs, columns = repcolumns)\n",
        "df_scale = pd.DataFrame(x_scaled, columns = repcolumns)\n",
        "\n",
        "dfL = [dfnorm,df_abs,df_scale]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03SRRxzrukAg",
        "colab_type": "text"
      },
      "source": [
        "Geração dos kfolds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQnbtzKStbp_",
        "colab_type": "code",
        "outputId": "b8be2cc1-588b-41ec-d1fc-01171c49a388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold \n",
        "\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "kf = KFold(n_splits = 10, shuffle = True, random_state = 2)\n",
        "X_index = dfnorm.index\n",
        "Y_index = dfclass.index\n",
        "\n",
        "for df in dfL:\n",
        "  for Features, Labels in skf.split(X_index,Y_index):\n",
        "    X_train, X_test = df.iloc[Features], df.iloc[Labels]\n",
        "    y_train, y_test = dfclass.iloc[Features], dfclass.iloc[Labels]\n",
        "\n",
        "\n",
        "Features = next(kf.split(X_index))\n",
        "Labels = next(kf.split(Y_index))\n",
        "\n",
        "X_train_N = dfnorm.iloc[Features[0]]\n",
        "X_test_N = dfnorm.iloc[Features[1]]\n",
        "\n",
        "X_train_Abs = df_abs.iloc[Features[0]]\n",
        "X_test_Abs = df_abs.iloc[Features[1]]\n",
        "\n",
        "X_train_S = df_scale.iloc[Features[0]]\n",
        "X_test_S = df_scale.iloc[Features[1]]\n",
        "\n",
        "Y_train = dfclass.iloc[Labels[0]]\n",
        "Y_test = dfclass.iloc[Labels[1]]\n",
        "\n",
        "X_trainL = []\n",
        "X_trainL.append([X_train_N,X_test_N])\n",
        "X_trainL.append([X_train_Abs,X_test_Abs])\n",
        "X_trainL.append([X_train_S,X_test_S])\n",
        "\n",
        "\n",
        "pl.plot(X_train_N['RNA4'],'bo')\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-7a413c67e37f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    649\u001b[0m             raise ValueError(\"n_splits=%d cannot be greater than the\"\n\u001b[1;32m    650\u001b[0m                              \u001b[0;34m\" number of members in each class.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m                              % (self.n_splits))\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             warnings.warn((\"The least populated class in y has only %d\"\n",
            "\u001b[0;31mValueError\u001b[0m: n_splits=5 cannot be greater than the number of members in each class."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6NZFbb3FU3x",
        "colab_type": "code",
        "outputId": "b3705d96-1d0e-42a5-e162-a48db81de425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "from rlscore.learner import RLS\n",
        "from rlscore.measure import sqerror\n",
        "from rlscore.learner import LeaveOneOutRLS\n",
        "\n",
        "regparams = [2.**i for i in range(-15, 16)]\n",
        "for X_train in X_trainL:\n",
        "  learner = RLS(X_train[0], Y_train, kernel=\"PolynomialKernel\", regparam = 100, gamma=1.0, coef0=1.0, degree=2)\n",
        "  P_loo = learner.leave_one_out()\n",
        "  P_test = learner.predict(X_train[1])\n",
        "  print(\"leave-one-out error %f\" %sqerror(Y_train, P_loo))\n",
        "  print(\"test error %f\" %sqerror(Y_test, P_test))\n",
        "  \n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "leave-one-out error 1.291374\n",
            "test error 1.321862\n",
            "leave-one-out error 1.297996\n",
            "test error 1.314215\n",
            "leave-one-out error 1.343569\n",
            "test error 1.334558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLEMFavwXuRx",
        "colab_type": "code",
        "outputId": "396fb3f0-d663-4d41-8a64-0844b329e24c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "  regparams = [2.**i for i in range(-15, 16)]\n",
        "  gammas = regparams\n",
        "  best_regparam = None\n",
        "  best_gamma = None\n",
        "  best_error = float(\"inf\")\n",
        "  best_learner = None\n",
        "  for gamma in gammas:\n",
        "      \n",
        "      learner = LeaveOneOutRLS(X_train, Y_train, kernel=\"GaussianKernel\", gamma=gamma, regparams=regparams)\n",
        "      e = np.min(learner.cv_performances)\n",
        "      if e < best_error:\n",
        "          best_error = e\n",
        "          best_regparam = learner.regparam\n",
        "          best_gamma = gamma\n",
        "          best_learner = learner\n",
        "P_test = best_learner.predict(X_test)\n",
        "print(\"best parameters gamma %f regparam %f\" %(best_gamma, best_regparam))\n",
        "print(\"best leave-one-out error %f\" %best_error)\n",
        "print(\"test error %f\" %sqerror(Y_test, P_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best parameters gamma 0.000031 regparam 1.000000\n",
            "best leave-one-out error 1.259181\n",
            "test error 1.257212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD8aVP-e6MxU",
        "colab_type": "text"
      },
      "source": [
        "Naive-Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0kO2Se46R18",
        "colab_type": "code",
        "outputId": "b2e29cdf-f8fd-47b7-82dd-1a73892d252e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "for df in dfL:\n",
        "  X_train,X_test,Y_train,Y_test = train_test_split(df,dfclass, test_size = 0.3, random_state = 900)\n",
        "  \n",
        "  gnb = GaussianNB()\n",
        "\n",
        "  gnb.fit(X_train, Y_train)\n",
        "\n",
        "  y_pred = gnb.predict(X_test)\n",
        "\n",
        "  print('Accuracy GaussianNB: {}'.format(metrics.accuracy_score(Y_test, y_pred)))\n",
        "\n",
        "  gnb = MultinomialNB()\n",
        "\n",
        "  gnb.fit(X_train, Y_train)\n",
        "\n",
        "  y_pred = gnb.predict(X_test)\n",
        "\n",
        "  print('Accuracy MultinominalNB: {}'.format(metrics.accuracy_score(Y_test, y_pred)))\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy GaussianNB: 0.28125\n",
            "Accuracy MultinominalNB: 0.24759615384615385\n",
            "Accuracy GaussianNB: 0.2548076923076923\n",
            "Accuracy MultinominalNB: 0.27163461538461536\n",
            "Accuracy GaussianNB: 0.2548076923076923\n",
            "Accuracy MultinominalNB: 0.28365384615384615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E288HjBPsocs",
        "colab_type": "text"
      },
      "source": [
        "Random Forrest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLu_i0assqzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "3496d291-6863-4f70-d943-2206db8cc9bf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "estimators =[100,200,500,800]\n",
        "\n",
        "for df in dfL:\n",
        "  for n in estimators:\n",
        "    train_features, test_features, train_labels, test_labels = train_test_split(df, dfclass, test_size = 0.25, random_state = 42)\n",
        "    rf = RandomForestClassifier(n_estimators=n)\n",
        "\n",
        "    rf.fit(train_features,train_labels)\n",
        "    predictions = rf.predict(test_features)\n",
        "    print('Accuracy com estimator {} : {}'.format(n,metrics.accuracy_score(test_labels, predictions)))\n",
        "  "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy com estimator 100 : 0.29394812680115273\n",
            "Accuracy com estimator 200 : 0.29394812680115273\n",
            "Accuracy com estimator 500 : 0.2824207492795389\n",
            "Accuracy com estimator 800 : 0.3285302593659942\n",
            "Accuracy com estimator 100 : 0.24495677233429394\n",
            "Accuracy com estimator 200 : 0.2478386167146974\n",
            "Accuracy com estimator 500 : 0.26512968299711814\n",
            "Accuracy com estimator 800 : 0.24495677233429394\n",
            "Accuracy com estimator 100 : 0.25936599423631124\n",
            "Accuracy com estimator 200 : 0.2737752161383285\n",
            "Accuracy com estimator 500 : 0.2478386167146974\n",
            "Accuracy com estimator 800 : 0.2737752161383285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIo5PLfFtuzk",
        "colab_type": "text"
      },
      "source": [
        "KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFxR8gjgtw3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "neighbors = [1,3,5,10]\n",
        "\n",
        "for df in dfL:\n",
        "  for n in neighbors:\n",
        "    train_features, test_features, train_labels, test_labels = train_test_split(df, dfclass, test_size = 0.25, random_state = 42)\n",
        "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "    neigh.fit(train_features, train_labels)\n",
        "    y_predic = neigh.predict(test_features)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}