{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Projeto_IA .ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUYiLuy_KfJ",
        "colab_type": "text"
      },
      "source": [
        "Projeto de predição de grau de estado deterioração do figado devido ao HCV\n",
        "\n",
        "Equipe: Daniel Lemos,\n",
        "        Rafael Targino\n",
        "        \n",
        "Data_Set: https://archive.ics.uci.edu/ml/machine-learning-databases/00503/HCV-Egy-Data.zip\n",
        "\n",
        "\n",
        "Passos:\n",
        "Ler os dados e normalizá-los cross-validation 10 folds\n",
        "Utilizar os seguintes algoritimos:\n",
        "1- KNN variando o K(1,3,5,10)\n",
        "2- Naive-Bayes\n",
        "3- Arvore de Decisão (Random Forrest) variando o numero de florestas\n",
        "4- RLScore(variando o numero de kernels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKKUBivC_KfP",
        "colab_type": "code",
        "outputId": "bbad76ee-d9fd-4fb6-c617-b5c3be767bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!pip install rlscore\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import preprocessing\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pl\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rlscore\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/25/bdf769f00b65602aa9fa7a1c674c6a508c427249e1ee8f2e1e1d7adcadad/rlscore-0.8.1.tar.gz (778kB)\n",
            "\r\u001b[K     |▍                               | 10kB 13.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 7.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 10.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 5.8MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 9.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 10.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 11.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 102kB 9.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 112kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 122kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 153kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 163kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 174kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 184kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 204kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 215kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 225kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 235kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 245kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 256kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 276kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 286kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 296kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 307kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 317kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 327kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 337kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 348kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 358kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 368kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 378kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 389kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 399kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 409kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 419kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 430kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 440kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 450kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 460kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 471kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 481kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 491kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 501kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 512kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 522kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 532kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 542kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 552kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 563kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 573kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 583kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 593kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 604kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 614kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 624kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 634kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 645kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 655kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 665kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 675kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 686kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 696kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 706kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 716kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 727kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 737kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 747kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 757kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 768kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 788kB 9.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: rlscore\n",
            "  Building wheel for rlscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rlscore: filename=rlscore-0.8.1-cp36-cp36m-linux_x86_64.whl size=1824822 sha256=d83e2b6215db62fb3a012cf8e7bb014b063f13d9b0ce811f835dd76852b18cf6\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/d7/27/cd7b2182c3f5c012dbbf9a8507116b9c49140ffc733223c07b\n",
            "Successfully built rlscore\n",
            "Installing collected packages: rlscore\n",
            "Successfully installed rlscore-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFLWhXJIMtm0",
        "colab_type": "text"
      },
      "source": [
        "Base de dados de pacientes egípcios que foram submetidos a doses de tratamento para HCV cerca de 18 meses. A discretização deve ser aplicada com base em recomendações de especialistas; há um arquivo anexado mostra como.\n",
        "\n",
        "A base de dados reúne cerca de \n",
        "\n",
        "Os dados apresentão o estágio inicial da entrada dos pacientes e as taxas , o problema é diagnosticar o grau de degradação do fígado através dos exames previamente levantados, sem a necessidade de exame de ultrasom ou histológico, ou seja prever o resultado do exame histológio acelerando assim que tipo de tratamento aplicar.\n",
        "as classes são não fibroso que significa saldável, fibroso, fibroso com poucas cepas do vírus, fibroso com muitas cepas e cirrose.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8SQ07ME9uiL",
        "colab_type": "code",
        "outputId": "52775e6f-a664-4c50-d103-cefe7caae0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "df = pd.read_csv(\"https://drive.google.com/uc?authuser=0&id=1S2HnHU5zoI7ERYhVd8naSaUMt0eJZW3L&export=download\")\n",
        "\n",
        "columns = df.columns\n",
        "\n",
        "\n",
        "ax = df['Baselinehistological staging'].value_counts().plot.bar()\n",
        "print(ax)\n",
        "classes = df['Baselinehistological staging'].unique()\n",
        "\n",
        "index_amostra= list()\n",
        "index_1 = 0\n",
        "index_3 = 0\n",
        "index_4 = 0\n",
        "index_2 = 0\n",
        "for x in df.index:\n",
        "  if index_2<332:\n",
        "    if df.loc[x,'Baselinehistological staging'] == 2:\n",
        "      index_amostra.append(x)\n",
        "      index_2= index_2+1\n",
        "  if index_4<332:    \n",
        "    if df.loc[x,'Baselinehistological staging'] == 4:\n",
        "      index_amostra.append(x)\n",
        "      index_4 = index_4 +1\n",
        "  if index_3<332:\n",
        "    if df.loc[x,'Baselinehistological staging'] == 3:\n",
        "      index_amostra.append(x)\n",
        "      index_3 = index_3 +1\n",
        "  if index_1<332:\n",
        "    if df.loc[x,'Baselinehistological staging'] ==1:\n",
        "      index_amostra.append(x)\n",
        "      index_1 = index_1 +1\n",
        "dfAvalues = []\n",
        "for g in index_amostra:\n",
        "  dfAvalues.append(df.iloc[g].values)\n",
        "\n",
        "dfAmostra = pd.DataFrame(dfAvalues,columns=columns)\n",
        "print(dfAmostra)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AxesSubplot(0.125,0.125;0.775x0.755)\n",
            "      Age   Gender  ...  Baseline histological Grading  Baselinehistological staging\n",
            "0     56.0     1.0  ...                           13.0                           2.0\n",
            "1     46.0     1.0  ...                            4.0                           2.0\n",
            "2     57.0     1.0  ...                            4.0                           4.0\n",
            "3     49.0     2.0  ...                           10.0                           3.0\n",
            "4     59.0     1.0  ...                           11.0                           1.0\n",
            "...    ...     ...  ...                            ...                           ...\n",
            "1323  59.0     1.0  ...                           16.0                           2.0\n",
            "1324  46.0     1.0  ...                           11.0                           2.0\n",
            "1325  52.0     2.0  ...                           16.0                           2.0\n",
            "1326  55.0     1.0  ...                           10.0                           2.0\n",
            "1327  42.0     1.0  ...                            6.0                           2.0\n",
            "\n",
            "[1328 rows x 29 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD1CAYAAACrz7WZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ4a7JHXIcJekDhnuktQhw12SOvR/A4b84XVaTGQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-5pjiqxu0t0",
        "colab_type": "text"
      },
      "source": [
        "Preparação dos dados de três formas diferentes, sendo escalados entre 0 e 1, valores absolutos  e normalizados, gerando três dataframes diferentes para os testes, separação das labels do Features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPQzqa5Mobvv",
        "colab_type": "code",
        "outputId": "eba5c428-12ec-4072-bd22-d6aa0a380d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        }
      },
      "source": [
        "from sklearn import preprocessing\n",
        "dfclass = pd.Series(dfAmostra['Baselinehistological staging'])\n",
        "dfsclass = pd.DataFrame(dfAmostra.iloc[:,0:28]) \n",
        "\n",
        "columns = dfsclass.columns\n",
        "ax = dfclass.value_counts().plot.bar()\n",
        "print(ax)\n",
        "\n",
        "repcolumns = list()\n",
        "for index, column in enumerate(columns):\n",
        "  column = column.replace(\" \",\"\")\n",
        "  repcolumns.append(column)\n",
        "x = dfsclass.values\n",
        "x_scale = preprocessing.scale(dfsclass)\n",
        "x_normal = preprocessing.normalize(dfsclass, norm='l1')\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(dfsclass)\n",
        "x_abs = max_abs_scaler.fit_transform(dfsclass)\n",
        "\n",
        "\n",
        "dfnorm = pd.DataFrame(x_normal, columns = repcolumns)\n",
        "df_abs = pd.DataFrame(x_abs, columns = repcolumns)\n",
        "df_scale = pd.DataFrame(x_scaled, columns = repcolumns)\n",
        "\n",
        "dfL = {'Normalizado': dfnorm,'Valor_Absoluto': df_abs,'Escalado': df_scale}\n",
        "print(dfnorm)\n",
        "print(df_abs)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AxesSubplot(0.125,0.125;0.775x0.755)\n",
            "           Age        Gender  ...         RNAEF  BaselinehistologicalGrading\n",
            "0     0.000009  1.681519e-07  ...  8.407595e-07                 2.185975e-06\n",
            "1     0.000007  1.624454e-07  ...  5.049615e-03                 6.497816e-07\n",
            "2     0.000008  1.368967e-07  ...  7.650186e-02                 5.475869e-07\n",
            "3     0.000006  2.394474e-07  ...  6.971522e-02                 1.197237e-06\n",
            "4     0.000006  9.513845e-08  ...  2.310542e-02                 1.046523e-06\n",
            "...        ...           ...  ...           ...                          ...\n",
            "1323  0.000008  1.402701e-07  ...  4.887640e-02                 2.244321e-06\n",
            "1324  0.000008  1.732038e-07  ...  8.660189e-07                 1.905242e-06\n",
            "1325  0.000008  3.223431e-07  ...  6.394481e-02                 2.578745e-06\n",
            "1326  0.000009  1.640075e-07  ...  3.875054e-02                 1.640075e-06\n",
            "1327  0.000006  1.481106e-07  ...  2.376538e-02                 8.886634e-07\n",
            "\n",
            "[1328 rows x 28 columns]\n",
            "           Age  Gender  ...     RNAEF  BaselinehistologicalGrading\n",
            "0     0.918033     0.5  ...  0.000006                       0.8125\n",
            "1     0.754098     0.5  ...  0.038361                       0.2500\n",
            "2     0.934426     0.5  ...  0.689629                       0.2500\n",
            "3     0.803279     1.0  ...  0.718595                       0.6250\n",
            "4     0.967213     0.5  ...  0.299705                       0.6875\n",
            "...        ...     ...  ...       ...                          ...\n",
            "1323  0.967213     0.5  ...  0.430002                       1.0000\n",
            "1324  0.754098     0.5  ...  0.000006                       0.6875\n",
            "1325  0.852459     1.0  ...  0.489614                       1.0000\n",
            "1326  0.901639     0.5  ...  0.291575                       0.6250\n",
            "1327  0.688525     0.5  ...  0.198014                       0.3750\n",
            "\n",
            "[1328 rows x 28 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD+CAYAAADBCEVaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWqQ4S5JDfp/G8hAN55bL7gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03SRRxzrukAg",
        "colab_type": "text"
      },
      "source": [
        "Geração dos kfolds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0kO2Se46R18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def TesteNB(dfL,dl,skf):\n",
        "  from sklearn.model_selection import cross_val_score\n",
        "  import numpy\n",
        "  Result_cross_valG =[]\n",
        "  Result_cross_valM =[]\n",
        "  Result_AcG = []\n",
        "  Result_AcM = []\n",
        "  for Features, Labels in skf.split(dfL[dl],dfclass):\n",
        "    X_train, X_test = dfL[dl].iloc[Features], dfL[dl].iloc[Labels]\n",
        "    y_train, y_test = dfclass.iloc[Features], dfclass.iloc[Labels]\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "    y_predG = gnb.predict(X_test)\n",
        "    acuG = metrics.accuracy_score(y_test, y_predG)\n",
        "    Result_cross_valG.append(max(cross_val_score(gnb,dfL[dl],dfclass,cv=10)))\n",
        "    \n",
        "    if Result_AcG != []:\n",
        "      if max(Result_AcG)<acuG:\n",
        "        Result_AcG.append(acuG)\n",
        "    else:\n",
        "      Result_AcG.append(acuG)\n",
        "\n",
        "    gnm = MultinomialNB()\n",
        "    gnm.fit(X_train, y_train)\n",
        "    y_predM = gnb.predict(X_test)\n",
        "    acuM = metrics.accuracy_score(y_test,y_predM)\n",
        "    Result_cross_valM.append(max(cross_val_score(gnm,dfL[dl],dfclass,cv=10)))\n",
        "    if Result_AcM != []:\n",
        "      if max(Result_AcM)<acuM:\n",
        "        Result_AcM.append(acuM)\n",
        "    else:\n",
        "      Result_AcM.append(acuM)\n",
        "\n",
        "  Result_cross_in_NBG = max(Result_cross_valG)\n",
        "  Result_cross_in_NBM = max(Result_cross_valM)\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "  return [Result_cross_in_NBG,Result_cross_in_NBM]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBhv4DiMqxC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rlscore.learner import LeaveOneOutRLS\n",
        "from rlscore.measure import ova_accuracy\n",
        "from rlscore.utilities.multiclass import to_one_vs_all\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def Testerls(dfL, dl, skf):\n",
        "  Result_Acu=[]\n",
        "  Result_cross_RLS=[]\n",
        "  for Features, Labels in skf.split(dfL[dl],dfclass):\n",
        "    X_train, X_test = dfL[dl].iloc[Features], dfL[dl].iloc[Labels]\n",
        "    y_train, y_test = dfclass.iloc[Features], dfclass.iloc[Labels]\n",
        "    y_train = to_one_vs_all(y_train, False)\n",
        "    y_test = to_one_vs_all(y_test, False)\n",
        "    regparams = [2.**i for i in range(-15, 16)]\n",
        "    learner = LeaveOneOutRLS(X_train, y_train, regparams=regparams, measure=ova_accuracy)\n",
        "    P_test = learner.predict(X_test)\n",
        "    acu = ova_accuracy(y_test, P_test)\n",
        "   # print(confusion_matrix(y_test,P_test))\n",
        "    if Result_Acu != []:\n",
        "      if max(Result_Acu)<acu:\n",
        "        Result_Acu.append(acu)\n",
        "    else:\n",
        "      Result_Acu.append(acu)\n",
        "  return max(Result_Acu)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQnbtzKStbp_",
        "colab_type": "code",
        "outputId": "2c31790e-0ef3-4e43-b9f5-069d1387b4ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from rlscore.learner import LeaveOneOutRLS\n",
        "from rlscore.measure import ova_accuracy\n",
        "from rlscore.utilities.multiclass import to_one_vs_all\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10,shuffle=True)\n",
        "Resultado_NB={}\n",
        "Resultado_Rls={}\n",
        "Resultado_Rf = {}\n",
        "X_index = dfnorm.index\n",
        "Y_index = dfclass.index\n",
        "estimators =[100,200,500,800]\n",
        "neighbors = [1,3,5,10]\n",
        "\n",
        "\n",
        "\n",
        "for dl in dfL:\n",
        "  Resultado_NB[dl] = TesteNB(dfL,dl,skf)\n",
        "  Resultado_Rls[dl] =Testerls(dfL,dl,skf)\n",
        "  #Resultado_Rf[dl] = TesteRF(dfL,dl,skf)\n",
        "print(Resultado_NB)\n",
        "print(Resultado_Rls)  \n",
        "\n",
        "Resul_NB = pd.DataFrame(Resultado_NB.values(),columns=['Gaussiano','Multinomial'],index=['Normalizado','Valor_Absoluto','Escalado'])\n",
        "Resul_NB.to_csv('AcuNB.csv',sep='\\t', encoding='utf-8')\n",
        "Resul_Rls = pd.DataFrame(Resultado_Rls.values(),index=['Normalizado', 'Valor_Absoluto','Escalado'],columns=['Acuracia'])\n",
        "\n",
        "print(Resul_NB.plot.bar())\n",
        "print(Resul_Rls.plot.bar())\n",
        "\n",
        "'''for dl in dfL:\n",
        "  \n",
        "   \n",
        "\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "    y_pred = gnb.predict(X_test)\n",
        "    acu = metrics.accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy GaussianNB: {}'.format(acu))\n",
        "\n",
        "    gnb = MultinomialNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "    y_pred = gnb.predict(X_test)\n",
        "    print('Accuracy MultinominalNB: {}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
        "\n",
        "    for n in estimators:\n",
        "      rf = RandomForestClassifier(n_estimators=n)\n",
        "      rf.fit(X_train,y_train)\n",
        "      predictions = rf.predict(X_test)\n",
        "      print('Accuracy com estimator {} : {}'.format(n,metrics.accuracy_score(y_test, predictions)))\n",
        "\n",
        "\n",
        "    y_train = to_one_vs_all(y_train, False)\n",
        "    y_test = to_one_vs_all(y_test, False)\n",
        "    regparams = [2.**i for i in range(-15, 16)]\n",
        "    learner = LeaveOneOutRLS(X_train, y_train, regparams=regparams, measure=ova_accuracy)\n",
        "    P_test = learner.predict(X_test)\n",
        "      \n",
        "    print(\"test set accuracy {}\".format(ova_accuracy(y_test, P_test)) )\n",
        "\n",
        "    \n",
        "  \n",
        "    y_train = to_one_vs_all(y_train, False)\n",
        "    y_test = to_one_vs_all(y_test, False)\n",
        "    regparams = [2.**i for i in range(-15, 16)]\n",
        "    learner = LeaveOneOutRLS(X_train, y_train, regparams=regparams, measure=ova_accuracy)\n",
        "    P_test = learner.predict(X_test)\n",
        "      \n",
        "    print(\"test set accuracy {}\".format(ova_accuracy(y_test, P_test)) )\n",
        "\n",
        "    for n in neighbors:\n",
        "      \n",
        "      neigh = KNeighborsClassifier(n_neighbors=n)\n",
        "      neigh.fit(X_train, y_train)\n",
        "      y_predic = neigh.predict(X_test,y_test)\n",
        "  '''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'Normalizado': [0.3181818181818182, 0.30303030303030304], 'Valor_Absoluto': [0.3106060606060606, 0.2878787878787879], 'Escalado': [0.3106060606060606, 0.3333333333333333]}\n",
            "{'Normalizado': 0.3484848484848485, 'Valor_Absoluto': 0.3484848484848485, 'Escalado': 0.3333333333333333}\n",
            "AxesSubplot(0.125,0.125;0.775x0.755)\n",
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for dl in dfL:\\n  \\n   \\n\\n    gnb = GaussianNB()\\n    gnb.fit(X_train, y_train)\\n    y_pred = gnb.predict(X_test)\\n    acu = metrics.accuracy_score(y_test, y_pred)\\n    print(\\'Accuracy GaussianNB: {}\\'.format(acu))\\n\\n    gnb = MultinomialNB()\\n    gnb.fit(X_train, y_train)\\n    y_pred = gnb.predict(X_test)\\n    print(\\'Accuracy MultinominalNB: {}\\'.format(metrics.accuracy_score(y_test, y_pred)))\\n\\n    for n in estimators:\\n      rf = RandomForestClassifier(n_estimators=n)\\n      rf.fit(X_train,y_train)\\n      predictions = rf.predict(X_test)\\n      print(\\'Accuracy com estimator {} : {}\\'.format(n,metrics.accuracy_score(y_test, predictions)))\\n\\n\\n    y_train = to_one_vs_all(y_train, False)\\n    y_test = to_one_vs_all(y_test, False)\\n    regparams = [2.**i for i in range(-15, 16)]\\n    learner = LeaveOneOutRLS(X_train, y_train, regparams=regparams, measure=ova_accuracy)\\n    P_test = learner.predict(X_test)\\n      \\n    print(\"test set accuracy {}\".format(ova_accuracy(y_test, P_test)) )\\n\\n    \\n  \\n    y_train = to_one_vs_all(y_train, False)\\n    y_test = to_one_vs_all(y_test, False)\\n    regparams = [2.**i for i in range(-15, 16)]\\n    learner = LeaveOneOutRLS(X_train, y_train, regparams=regparams, measure=ova_accuracy)\\n    P_test = learner.predict(X_test)\\n      \\n    print(\"test set accuracy {}\".format(ova_accuracy(y_test, P_test)) )\\n\\n    for n in neighbors:\\n      \\n      neigh = KNeighborsClassifier(n_neighbors=n)\\n      neigh.fit(X_train, y_train)\\n      y_predic = neigh.predict(X_test,y_test)\\n  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAE9CAYAAAAF/alEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncw56M7Oc+/9B8cCd7AD+mwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAE5CAYAAACebOtSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLu_i0assqzj",
        "colab_type": "code",
        "outputId": "99406b53-7754-42d0-c6e1-9da75a7dd523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def TesteRF(dfL,dl,skf):\n",
        "  \n",
        "  estimators =[100,200,500,800]\n",
        "  Result_Acu = {}\n",
        "  Result_cross_RF ={}\n",
        "  for Features, Labels in skf.split(dfL[dl],dfclass):\n",
        "    X_train, X_test = dfL[dl].iloc[Features], dfL[dl].iloc[Labels]\n",
        "    y_train, y_test = dfclass.iloc[Features], dfclass.iloc[Labels]\n",
        "    for n in estimators:\n",
        "      rf = RandomForestClassifier(n_estimators=n)\n",
        "      rf.fit(X_train,y_train)\n",
        "      predictions = rf.predict(X_test)\n",
        "      acu = metrics.accuracy_score(y_test, predictions)\n",
        "      Result_cross_RF[n]= max(cross_val_score(rf,dfL[dl],dfclass,cv=2))\n",
        "      if n in Result_Acu:\n",
        "        if Result_Acu[n]>acu:\n",
        "            Result_Acu[n]=acu\n",
        "      else:\n",
        "        Result_Acu[n]=acu\n",
        "     \n",
        "  return(Result_Acu,Result_cross_RF)\n",
        "print(TesteRF(dfL,dl,skf))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-cc01ad32d6a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResult_Acu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mResult_cross_RF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTesteRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-131-cc01ad32d6a2>\u001b[0m in \u001b[0;36mTesteRF\u001b[0;34m(dfL, dl, skf)\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0macu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mResult_cross_RF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdfL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdfclass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mResult_Acu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mResult_Acu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0macu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wToYQZE0aewH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E288HjBPsocs",
        "colab_type": "text"
      },
      "source": [
        "Random Forrest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIo5PLfFtuzk",
        "colab_type": "text"
      },
      "source": [
        "KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFxR8gjgtw3X",
        "colab_type": "code",
        "outputId": "3f822825-a010-4cf1-97ec-40aa19ccf80c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "neighbors = [1,3,5,10]\n",
        "\n",
        "for df in dfL:\n",
        "  for n in neighbors:\n",
        "    train_features, test_features, train_labels, test_labels = train_test_split(df, dfclass, test_size = 0.25, random_state = 42)\n",
        "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "    neigh.fit(train_features, train_labels)\n",
        "    y_predic = neigh.predict(test_features)\n",
        "    acc = accuracy_score(test_labels,y_predic)    \n",
        "    print(acc)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.22590361445783133\n",
            "0.24096385542168675\n",
            "0.24096385542168675\n",
            "0.24096385542168675\n",
            "0.24096385542168675\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}