{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Projeto_IA .ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUYiLuy_KfJ",
        "colab_type": "text"
      },
      "source": [
        "Projeto de predição de grau de estado deterioração do figado devido ao HCV\n",
        "\n",
        "Equipe: Daniel Lemos,\n",
        "        Rafael Targino\n",
        "        \n",
        "Data_Set: https://archive.ics.uci.edu/ml/machine-learning-databases/00503/HCV-Egy-Data.zip\n",
        "\n",
        "\n",
        "Passos:\n",
        "Ler os dados e normalizá-los cross-validation 10 folds\n",
        "Utilizar os seguintes algoritimos:\n",
        "1- KNN variando o K(1,3,5,10)\n",
        "2- Naive-Bayes\n",
        "3- Arvore de Decisão (Random Forrest) variando o numero de florestas\n",
        "4- RLScore(variando o numero de kernels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKKUBivC_KfP",
        "colab_type": "code",
        "outputId": "3dd70365-12b0-4f15-b1cd-dcfe111a22e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "!pip install rlscore\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import preprocessing\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pl\n",
        "%matplotlib inline"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rlscore in /usr/local/lib/python3.6/dist-packages (0.8.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-589dc4b6a375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.pyplot.bar'; 'matplotlib.pyplot' is not a package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFLWhXJIMtm0",
        "colab_type": "text"
      },
      "source": [
        "Base de dados de pacientes egípcios que foram submetidos a doses de tratamento para HCV cerca de 18 meses. A discretização deve ser aplicada com base em recomendações de especialistas; há um arquivo anexado mostra como.\n",
        "\n",
        "A base de dados reúne cerca de \n",
        "\n",
        "Os dados apresentão o estágio inicial da entrada dos pacientes e as taxas , o problema é diagnosticar o grau de degradação do fígado através dos exames previamente levantados, sem a necessidade de exame de ultrasom ou histológico, ou seja prever o resultado do exame histológio acelerando assim que tipo de tratamento aplicar.\n",
        "as classes são não fibroso que significa saldável, fibroso, fibroso com poucas cepas do vírus, fibroso com muitas cepas e cirrose.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8SQ07ME9uiL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "d32cf3f6-b5ce-4b45-cdfd-3a1d5990abe0"
      },
      "source": [
        "df = pd.read_csv(\"https://drive.google.com/uc?authuser=0&id=1S2HnHU5zoI7ERYhVd8naSaUMt0eJZW3L&export=download\")\n",
        "columns = df.columns\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "classes = df['Baselinehistological staging'].unique()\n",
        "\n",
        "print(classes)\n",
        "index_amostra= list()\n",
        "index_1 = 0\n",
        "index_3 = 0\n",
        "index_4 = 0\n",
        "index_2 = 0\n",
        "for x in df.index:\n",
        "  if index_2<332:\n",
        "    if df.loc[x,'Baselinehistological staging'] == 2:\n",
        "      index_amostra.append(x)\n",
        "      index_2= index_2+1\n",
        "  if index_4<332:    \n",
        "    if df.loc[x,'Baselinehistological staging'] == 4:\n",
        "      index_amostra.append(x)\n",
        "      index_4 = index_4 +1\n",
        "  if index_3<332:\n",
        "    if df.loc[x,'Baselinehistological staging'] == 3:\n",
        "      index_amostra.append(x)\n",
        "      index_3 = index_3 +1\n",
        "  if index_1<332:\n",
        "    if df.loc[x,'Baselinehistological staging'] ==1:\n",
        "      index_amostra.append(x)\n",
        "      index_1 = index_1 +1\n",
        "dfAvalues = []\n",
        "for g in index_amostra:\n",
        "  dfAvalues.append(df.iloc[g].values)\n",
        "\n",
        "dfAmostra = pd.DataFrame(dfAvalues,columns=columns)\n",
        "print(dfAmostra)\n"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 4 3 1]\n",
            "      Age   Gender  ...  Baseline histological Grading  Baselinehistological staging\n",
            "0     56.0     1.0  ...                           13.0                           2.0\n",
            "1     46.0     1.0  ...                            4.0                           2.0\n",
            "2     57.0     1.0  ...                            4.0                           4.0\n",
            "3     49.0     2.0  ...                           10.0                           3.0\n",
            "4     59.0     1.0  ...                           11.0                           1.0\n",
            "...    ...     ...  ...                            ...                           ...\n",
            "1323  59.0     1.0  ...                           16.0                           2.0\n",
            "1324  46.0     1.0  ...                           11.0                           2.0\n",
            "1325  52.0     2.0  ...                           16.0                           2.0\n",
            "1326  55.0     1.0  ...                           10.0                           2.0\n",
            "1327  42.0     1.0  ...                            6.0                           2.0\n",
            "\n",
            "[1328 rows x 29 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-5pjiqxu0t0",
        "colab_type": "text"
      },
      "source": [
        "Preparação dos dados de três formas diferentes, sendo escalados entre 0 e 1, valores absolutos  e normalizados, gerando três dataframes diferentes para os testes, separação das labels do Features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPQzqa5Mobvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "18d40f79-85d0-4a14-e3ea-883b01d432c0"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "dfclass = pd.Series(dfAmostra['Baselinehistological staging'])\n",
        "dfsclass = pd.DataFrame(dfAmostra.iloc[:,0:28]) \n",
        "\n",
        "columns = dfsclass.columns\n",
        "ax = dfclass.value_counts()\n",
        "print(ax)\n",
        "\n",
        "repcolumns = list()\n",
        "for index, column in enumerate(columns):\n",
        "  column = column.replace(\" \",\"\")\n",
        "  repcolumns.append(column)\n",
        "x = dfsclass.values\n",
        "x_scale = preprocessing.scale(dfsclass)\n",
        "x_normal = preprocessing.normalize(dfsclass, norm='l1')\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(dfsclass)\n",
        "x_abs = max_abs_scaler.fit_transform(dfsclass)\n",
        "\n",
        "\n",
        "dfnorm = pd.DataFrame(x_normal, columns = repcolumns)\n",
        "df_abs = pd.DataFrame(x_abs, columns = repcolumns)\n",
        "df_scale = pd.DataFrame(x_scaled, columns = repcolumns)\n",
        "\n",
        "dfL = [dfnorm,df_abs,df_scale]\n",
        "\n",
        "\n"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0    332\n",
            "3.0    332\n",
            "4.0    332\n",
            "2.0    332\n",
            "Name: Baselinehistological staging, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03SRRxzrukAg",
        "colab_type": "text"
      },
      "source": [
        "Geração dos kfolds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQnbtzKStbp_",
        "colab_type": "code",
        "outputId": "01f3fb40-fa3b-4f83-e881-fc76cdd90139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from rlscore.learner import LeaveOneOutRLS\n",
        "from rlscore.measure import ova_accuracy\n",
        "from rlscore.utilities.multiclass import to_one_vs_all\n",
        "from sklearn import metrics\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10)\n",
        "kf = KFold(n_splits = 10, shuffle = True, random_state = 2)\n",
        "X_index = dfnorm.index\n",
        "Y_index = dfclass.index\n",
        "estimators =[100,200,500,800]\n",
        "neighbors = [1,3,5,10]\n",
        "for dl in dfL:\n",
        "  for Features, Labels in skf.split(dl,dfclass):\n",
        "    X_train, X_test = dl.iloc[Features], dl.iloc[Labels]\n",
        "    y_train, y_test = dfclass.iloc[Features], dfclass.iloc[Labels]\n",
        "\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "    y_pred = gnb.predict(X_test)\n",
        "    \n",
        "    print('Accuracy GaussianNB: {}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
        "\n",
        "    gnb = MultinomialNB()\n",
        "\n",
        "    gnb.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = gnb.predict(X_test)\n",
        "\n",
        "    print('Accuracy MultinominalNB: {}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
        "\n",
        "    for n in estimators:\n",
        "      \n",
        "      rf = RandomForestClassifier(n_estimators=n)\n",
        "\n",
        "      rf.fit(X_train,y_train)\n",
        "      predictions = rf.predict(X_test)\n",
        "      print('Accuracy com estimator {} : {}'.format(n,metrics.accuracy_score(y_test, predictions)))\n",
        "\n",
        "    y_train = to_one_vs_all(y_train, False)\n",
        "    y_test = to_one_vs_all(y_test, False)\n",
        "    regparams = [2.**i for i in range(-15, 16)]\n",
        "    learner = LeaveOneOutRLS(X_train, y_train, regparams=regparams, measure=ova_accuracy)\n",
        "    P_test = learner.predict(X_test)\n",
        "      \n",
        "    print(\"test set accuracy {}\".format(ova_accuracy(y_test, P_test)) )\n",
        "\n",
        "    for n in neighbors:\n",
        "      \n",
        "      neigh = KNeighborsClassifier(n_neighbors=n)\n",
        "      neigh.fit(X_train, y_train)\n",
        "      y_predic = neigh.predict(X_test,y_test)\n",
        "  \n"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy GaussianNB: 0.19117647058823528\n",
            "Accuracy MultinominalNB: 0.2647058823529412\n",
            "Accuracy com estimator 100 : 0.22058823529411764\n",
            "Accuracy com estimator 200 : 0.25735294117647056\n",
            "Accuracy com estimator 500 : 0.2647058823529412\n",
            "Accuracy com estimator 800 : 0.25735294117647056\n",
            "test set accuracy 0.3161764705882353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-249-cb6236ae18e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0mneigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0my_predic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6NZFbb3FU3x",
        "colab_type": "code",
        "outputId": "b01cef8b-0b69-4be8-a6a4-6e73addd5fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from rlscore.learner import LeaveOneOutRLS\n",
        "from rlscore.measure import ova_accuracy\n",
        "from rlscore.utilities.multiclass import to_one_vs_all\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_rls():\n",
        "   \n",
        "    for Features, Labels in skf.split(dl,dfclass):\n",
        "      X_train, X_test = dfsclass.iloc[Features], dfsclass.iloc[Labels]\n",
        "      y_train, y_test = dfclass.iloc[Features], dfclass.iloc[Labels]\n",
        "      y_train = to_one_vs_all(y_train, False)\n",
        "      y_test = to_one_vs_all(y_test, False)\n",
        "      regparams = [2.**i for i in range(-15, 16)]\n",
        "      learner = LeaveOneOutRLS(X_train, y_train, regparams=regparams, measure=ova_accuracy)\n",
        "      P_test = learner.predict(X_test)\n",
        "      \n",
        "      print(\"test set accuracy {}\".format(ova_accuracy(y_test, P_test)) )\n",
        "\n",
        "train_rls()"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n",
            "/usr/local/lib/python3.6/dist-packages/rlscore/utilities/array_tools.py:43: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  if not np.issubdtype(A.dtype, int) and not np.issubdtype(A.dtype, float):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test set accuracy 0.2727272727272727\n",
            "test set accuracy 0.23484848484848486\n",
            "test set accuracy 0.2803030303030303\n",
            "test set accuracy 0.25757575757575757\n",
            "test set accuracy 0.29545454545454547\n",
            "test set accuracy 0.19696969696969696\n",
            "test set accuracy 0.25757575757575757\n",
            "test set accuracy 0.2196969696969697\n",
            "test set accuracy 0.2196969696969697\n",
            "test set accuracy 0.29545454545454547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD8aVP-e6MxU",
        "colab_type": "text"
      },
      "source": [
        "Naive-Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0kO2Se46R18",
        "colab_type": "code",
        "outputId": "b2e29cdf-f8fd-47b7-82dd-1a73892d252e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "for df in dfL:\n",
        "  X_train,X_test,Y_train,Y_test = train_test_split(df,dfclass, test_size = 0.3, random_state = 900)\n",
        "  \n",
        "  gnb = GaussianNB()\n",
        "\n",
        "  gnb.fit(X_train, Y_train)\n",
        "\n",
        "  y_pred = gnb.predict(X_test)\n",
        "\n",
        "  print('Accuracy GaussianNB: {}'.format(metrics.accuracy_score(Y_test, y_pred)))\n",
        "\n",
        "  gnb = MultinomialNB()\n",
        "\n",
        "  gnb.fit(X_train, Y_train)\n",
        "\n",
        "  y_pred = gnb.predict(X_test)\n",
        "\n",
        "  print('Accuracy MultinominalNB: {}'.format(metrics.accuracy_score(Y_test, y_pred)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy GaussianNB: 0.28125\n",
            "Accuracy MultinominalNB: 0.24759615384615385\n",
            "Accuracy GaussianNB: 0.2548076923076923\n",
            "Accuracy MultinominalNB: 0.27163461538461536\n",
            "Accuracy GaussianNB: 0.2548076923076923\n",
            "Accuracy MultinominalNB: 0.28365384615384615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E288HjBPsocs",
        "colab_type": "text"
      },
      "source": [
        "Random Forrest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLu_i0assqzj",
        "colab_type": "code",
        "outputId": "3496d291-6863-4f70-d943-2206db8cc9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "estimators =[100,200,500,800]\n",
        "\n",
        "for df in dfL:\n",
        "  for n in estimators:\n",
        "    train_features, test_features, train_labels, test_labels = train_test_split(df, dfclass, test_size = 0.25, random_state = 42)\n",
        "    rf = RandomForestClassifier(n_estimators=n)\n",
        "\n",
        "    rf.fit(train_features,train_labels)\n",
        "    predictions = rf.predict(test_features)\n",
        "    print('Accuracy com estimator {} : {}'.format(n,metrics.accuracy_score(test_labels, predictions)))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy com estimator 100 : 0.29394812680115273\n",
            "Accuracy com estimator 200 : 0.29394812680115273\n",
            "Accuracy com estimator 500 : 0.2824207492795389\n",
            "Accuracy com estimator 800 : 0.3285302593659942\n",
            "Accuracy com estimator 100 : 0.24495677233429394\n",
            "Accuracy com estimator 200 : 0.2478386167146974\n",
            "Accuracy com estimator 500 : 0.26512968299711814\n",
            "Accuracy com estimator 800 : 0.24495677233429394\n",
            "Accuracy com estimator 100 : 0.25936599423631124\n",
            "Accuracy com estimator 200 : 0.2737752161383285\n",
            "Accuracy com estimator 500 : 0.2478386167146974\n",
            "Accuracy com estimator 800 : 0.2737752161383285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIo5PLfFtuzk",
        "colab_type": "text"
      },
      "source": [
        "KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFxR8gjgtw3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "neighbors = [1,3,5,10]\n",
        "\n",
        "for df in dfL:\n",
        "  for n in neighbors:\n",
        "    train_features, test_features, train_labels, test_labels = train_test_split(df, dfclass, test_size = 0.25, random_state = 42)\n",
        "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "    neigh.fit(train_features, train_labels)\n",
        "    y_predic = neigh.predict(test_features)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}