{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Projeto_IA .ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUYiLuy_KfJ",
        "colab_type": "text"
      },
      "source": [
        "Projeto de predição de grau de estado deterioração do figado devido ao HCV\n",
        "\n",
        "Equipe: Daniel Lemos,\n",
        "        Rafael Targino\n",
        "        \n",
        "Data_Set: https://archive.ics.uci.edu/ml/machine-learning-databases/00503/HCV-Egy-Data.zip\n",
        "\n",
        "\n",
        "Passos:\n",
        "Ler os dados e normalizá-los cross-validation 10 folds\n",
        "Utilizar os seguintes algoritimos:\n",
        "1- KNN variando o K(1,3,5,10)\n",
        "2- Naive-Bayes\n",
        "3- Arvore de Decisão (Random Forrest) variando o numero de florestas\n",
        "4- RLScore(variando o numero de kernels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKKUBivC_KfP",
        "colab_type": "code",
        "outputId": "3dd70365-12b0-4f15-b1cd-dcfe111a22e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "!pip install rlscore\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import preprocessing\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pl\n",
        "%matplotlib inline"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rlscore in /usr/local/lib/python3.6/dist-packages (0.8.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-589dc4b6a375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.pyplot.bar'; 'matplotlib.pyplot' is not a package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFLWhXJIMtm0",
        "colab_type": "text"
      },
      "source": [
        "Base de dados de pacientes egípcios que foram submetidos a doses de tratamento para HCV cerca de 18 meses. A discretização deve ser aplicada com base em recomendações de especialistas; há um arquivo anexado mostra como.\n",
        "\n",
        "A base de dados reúne cerca de \n",
        "\n",
        "Os dados apresentão o estágio inicial da entrada dos pacientes e as taxas , o problema é diagnosticar o grau de degradação do fígado através dos exames previamente levantados, sem a necessidade de exame de ultrasom ou histológico, ou seja prever o resultado do exame histológio acelerando assim que tipo de tratamento aplicar.\n",
        "as classes são não fibroso que significa saldável, fibroso, fibroso com poucas cepas do vírus, fibroso com muitas cepas e cirrose.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8SQ07ME9uiL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a9b67682-9da0-40ed-efab-8b264b77be61"
      },
      "source": [
        "df = pd.read_csv(\"https://drive.google.com/uc?authuser=0&id=1S2HnHU5zoI7ERYhVd8naSaUMt0eJZW3L&export=download\")\n",
        "columns = df.columns\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "classes = df['Baselinehistological staging'].unique()\n",
        "\n",
        "print(classes)\n",
        "index_amostra= list()\n",
        "index_1 = 0\n",
        "index_3 = 0\n",
        "index_4 = 0\n",
        "index_2 = 0\n",
        "for x in df.index:\n",
        "  if index_2<330:\n",
        "    if df.loc[x,'Baselinehistological staging'] == 2:\n",
        "      index_amostra.append(x)\n",
        "      index_2= index_2+1\n",
        "  if index_4<330:    \n",
        "    if df.loc[x,'Baselinehistological staging'] == 4:\n",
        "      index_amostra.append(x)\n",
        "      index_4 = index_4 +1\n",
        "  if index_3<330:\n",
        "    if df.loc[x,'Baselinehistological staging'] == 3:\n",
        "      index_amostra.append(x)\n",
        "      index_3 = index_3 +1\n",
        "  if index_1<330:\n",
        "    if df.loc[x,'Baselinehistological staging'] ==1:\n",
        "      index_amostra.append(x)\n",
        "      index_1 = index_1 +1\n",
        "dfAvalues = []\n",
        "for g in index_amostra:\n",
        "  dfAvalues.append(df.iloc[g].values)\n",
        "\n",
        "dfAmostra = pd.DataFrame(dfAvalues,columns=columns)\n",
        "print(dfAmostra)\n"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 4 3 1]\n",
            "      Age   Gender  ...  Baseline histological Grading  Baselinehistological staging\n",
            "0     56.0     1.0  ...                           13.0                           2.0\n",
            "1     46.0     1.0  ...                            4.0                           2.0\n",
            "2     57.0     1.0  ...                            4.0                           4.0\n",
            "3     49.0     2.0  ...                           10.0                           3.0\n",
            "4     59.0     1.0  ...                           11.0                           1.0\n",
            "...    ...     ...  ...                            ...                           ...\n",
            "1315  58.0     1.0  ...                           15.0                           2.0\n",
            "1316  49.0     1.0  ...                            6.0                           2.0\n",
            "1317  59.0     1.0  ...                           16.0                           2.0\n",
            "1318  46.0     1.0  ...                           11.0                           2.0\n",
            "1319  52.0     2.0  ...                           16.0                           2.0\n",
            "\n",
            "[1320 rows x 29 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-5pjiqxu0t0",
        "colab_type": "text"
      },
      "source": [
        "Preparação dos dados de três formas diferentes, sendo escalados entre 0 e 1, valores absolutos  e normalizados, gerando três dataframes diferentes para os testes, separação das labels do Features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPQzqa5Mobvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "526b2cf3-2ed2-4238-be9b-fd30e3db064a"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "dfclass = pd.Series(dfAmostra['Baselinehistological staging'])\n",
        "dfsclass = pd.DataFrame(dfAmostra.iloc[:,0:28]) \n",
        "\n",
        "columns = dfsclass.columns\n",
        "ax = dfclass.value_counts()\n",
        "print(ax)\n",
        "\n",
        "repcolumns = list()\n",
        "for index, column in enumerate(columns):\n",
        "  column = column.replace(\" \",\"\")\n",
        "  repcolumns.append(column)\n",
        "x = dfsclass.values\n",
        "x_scale = preprocessing.scale(dfsclass)\n",
        "x_normal = preprocessing.normalize(dfsclass, norm='l1')\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(dfsclass)\n",
        "x_abs = max_abs_scaler.fit_transform(dfsclass)\n",
        "\n",
        "\n",
        "dfnorm = pd.DataFrame(x_normal, columns = repcolumns)\n",
        "df_abs = pd.DataFrame(x_abs, columns = repcolumns)\n",
        "df_scale = pd.DataFrame(x_scaled, columns = repcolumns)\n",
        "\n",
        "dfL = [dfnorm,df_abs,df_scale]\n",
        "\n",
        "\n"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0    330\n",
            "3.0    330\n",
            "4.0    330\n",
            "2.0    330\n",
            "Name: Baselinehistological staging, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03SRRxzrukAg",
        "colab_type": "text"
      },
      "source": [
        "Geração dos kfolds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQnbtzKStbp_",
        "colab_type": "code",
        "outputId": "4fe2d09a-8706-4d4f-a257-6cb857f55d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10)\n",
        "kf = KFold(n_splits = 10, shuffle = True, random_state = 2)\n",
        "X_index = dfnorm.index\n",
        "Y_index = dfclass.index\n",
        "estimators =[100,200,500,800]\n",
        "for dl in dfL:\n",
        "  for Features, Labels in skf.split(dl,dfclass):\n",
        "    X_train, X_test = dl.iloc[Features], dl.iloc[Labels]\n",
        "    y_train, y_test = dfclass.iloc[Features], dfclass.iloc[Labels]\n",
        "\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "    y_pred = gnb.predict(X_test)\n",
        "    \n",
        "    print('Accuracy GaussianNB: {}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
        "\n",
        "    gnb = MultinomialNB()\n",
        "\n",
        "    gnb.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = gnb.predict(X_test)\n",
        "\n",
        "    print('Accuracy MultinominalNB: {}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
        "\n",
        "    for n in estimators:\n",
        "      \n",
        "      rf = RandomForestClassifier(n_estimators=n)\n",
        "\n",
        "      rf.fit(X_train,y_train)\n",
        "      predictions = rf.predict(X_test)\n",
        "      print('Accuracy com estimator {} : {}'.format(n,metrics.accuracy_score(y_test, predictions)))\n",
        "  \n"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy GaussianNB: 0.21212121212121213\n",
            "Accuracy MultinominalNB: 0.25757575757575757\n",
            "Accuracy com estimator 100 : 0.2878787878787879\n",
            "Accuracy com estimator 200 : 0.3181818181818182\n",
            "Accuracy com estimator 500 : 0.25\n",
            "Accuracy com estimator 800 : 0.25\n",
            "Accuracy GaussianNB: 0.21212121212121213\n",
            "Accuracy MultinominalNB: 0.25\n",
            "Accuracy com estimator 100 : 0.23484848484848486\n",
            "Accuracy com estimator 200 : 0.25\n",
            "Accuracy com estimator 500 : 0.3106060606060606\n",
            "Accuracy com estimator 800 : 0.2727272727272727\n",
            "Accuracy GaussianNB: 0.26515151515151514\n",
            "Accuracy MultinominalNB: 0.30303030303030304\n",
            "Accuracy com estimator 100 : 0.30303030303030304\n",
            "Accuracy com estimator 200 : 0.26515151515151514\n",
            "Accuracy com estimator 500 : 0.23484848484848486\n",
            "Accuracy com estimator 800 : 0.25757575757575757\n",
            "Accuracy GaussianNB: 0.20454545454545456\n",
            "Accuracy MultinominalNB: 0.21212121212121213\n",
            "Accuracy com estimator 100 : 0.21212121212121213\n",
            "Accuracy com estimator 200 : 0.25757575757575757\n",
            "Accuracy com estimator 500 : 0.26515151515151514\n",
            "Accuracy com estimator 800 : 0.25757575757575757\n",
            "Accuracy GaussianNB: 0.2803030303030303\n",
            "Accuracy MultinominalNB: 0.23484848484848486\n",
            "Accuracy com estimator 100 : 0.25757575757575757\n",
            "Accuracy com estimator 200 : 0.29545454545454547\n",
            "Accuracy com estimator 500 : 0.29545454545454547\n",
            "Accuracy com estimator 800 : 0.2803030303030303\n",
            "Accuracy GaussianNB: 0.19696969696969696\n",
            "Accuracy MultinominalNB: 0.24242424242424243\n",
            "Accuracy com estimator 100 : 0.21212121212121213\n",
            "Accuracy com estimator 200 : 0.25757575757575757\n",
            "Accuracy com estimator 500 : 0.20454545454545456\n",
            "Accuracy com estimator 800 : 0.21212121212121213\n",
            "Accuracy GaussianNB: 0.23484848484848486\n",
            "Accuracy MultinominalNB: 0.2727272727272727\n",
            "Accuracy com estimator 100 : 0.2196969696969697\n",
            "Accuracy com estimator 200 : 0.26515151515151514\n",
            "Accuracy com estimator 500 : 0.2803030303030303\n",
            "Accuracy com estimator 800 : 0.2878787878787879\n",
            "Accuracy GaussianNB: 0.24242424242424243\n",
            "Accuracy MultinominalNB: 0.2196969696969697\n",
            "Accuracy com estimator 100 : 0.25\n",
            "Accuracy com estimator 200 : 0.2727272727272727\n",
            "Accuracy com estimator 500 : 0.24242424242424243\n",
            "Accuracy com estimator 800 : 0.26515151515151514\n",
            "Accuracy GaussianNB: 0.22727272727272727\n",
            "Accuracy MultinominalNB: 0.2878787878787879\n",
            "Accuracy com estimator 100 : 0.29545454545454547\n",
            "Accuracy com estimator 200 : 0.2803030303030303\n",
            "Accuracy com estimator 500 : 0.26515151515151514\n",
            "Accuracy com estimator 800 : 0.26515151515151514\n",
            "Accuracy GaussianNB: 0.30303030303030304\n",
            "Accuracy MultinominalNB: 0.3181818181818182\n",
            "Accuracy com estimator 100 : 0.2803030303030303\n",
            "Accuracy com estimator 200 : 0.3181818181818182\n",
            "Accuracy com estimator 500 : 0.3333333333333333\n",
            "Accuracy com estimator 800 : 0.3484848484848485\n",
            "Accuracy GaussianNB: 0.24242424242424243\n",
            "Accuracy MultinominalNB: 0.2878787878787879\n",
            "Accuracy com estimator 100 : 0.21212121212121213\n",
            "Accuracy com estimator 200 : 0.20454545454545456\n",
            "Accuracy com estimator 500 : 0.24242424242424243\n",
            "Accuracy com estimator 800 : 0.20454545454545456\n",
            "Accuracy GaussianNB: 0.2196969696969697\n",
            "Accuracy MultinominalNB: 0.2196969696969697\n",
            "Accuracy com estimator 100 : 0.3106060606060606\n",
            "Accuracy com estimator 200 : 0.2878787878787879\n",
            "Accuracy com estimator 500 : 0.30303030303030304\n",
            "Accuracy com estimator 800 : 0.25757575757575757\n",
            "Accuracy GaussianNB: 0.2803030303030303\n",
            "Accuracy MultinominalNB: 0.2803030303030303\n",
            "Accuracy com estimator 100 : 0.2727272727272727\n",
            "Accuracy com estimator 200 : 0.2878787878787879\n",
            "Accuracy com estimator 500 : 0.2878787878787879\n",
            "Accuracy com estimator 800 : 0.2803030303030303\n",
            "Accuracy GaussianNB: 0.19696969696969696\n",
            "Accuracy MultinominalNB: 0.20454545454545456\n",
            "Accuracy com estimator 100 : 0.20454545454545456\n",
            "Accuracy com estimator 200 : 0.2803030303030303\n",
            "Accuracy com estimator 500 : 0.25757575757575757\n",
            "Accuracy com estimator 800 : 0.2878787878787879\n",
            "Accuracy GaussianNB: 0.26515151515151514\n",
            "Accuracy MultinominalNB: 0.29545454545454547\n",
            "Accuracy com estimator 100 : 0.25\n",
            "Accuracy com estimator 200 : 0.2196969696969697\n",
            "Accuracy com estimator 500 : 0.2878787878787879\n",
            "Accuracy com estimator 800 : 0.3106060606060606\n",
            "Accuracy GaussianNB: 0.2727272727272727\n",
            "Accuracy MultinominalNB: 0.24242424242424243\n",
            "Accuracy com estimator 100 : 0.2196969696969697\n",
            "Accuracy com estimator 200 : 0.26515151515151514\n",
            "Accuracy com estimator 500 : 0.24242424242424243\n",
            "Accuracy com estimator 800 : 0.25757575757575757\n",
            "Accuracy GaussianNB: 0.19696969696969696\n",
            "Accuracy MultinominalNB: 0.22727272727272727\n",
            "Accuracy com estimator 100 : 0.21212121212121213\n",
            "Accuracy com estimator 200 : 0.23484848484848486\n",
            "Accuracy com estimator 500 : 0.25\n",
            "Accuracy com estimator 800 : 0.22727272727272727\n",
            "Accuracy GaussianNB: 0.20454545454545456\n",
            "Accuracy MultinominalNB: 0.23484848484848486\n",
            "Accuracy com estimator 100 : 0.25757575757575757\n",
            "Accuracy com estimator 200 : 0.2196969696969697\n",
            "Accuracy com estimator 500 : 0.2196969696969697\n",
            "Accuracy com estimator 800 : 0.22727272727272727\n",
            "Accuracy GaussianNB: 0.2196969696969697\n",
            "Accuracy MultinominalNB: 0.2803030303030303\n",
            "Accuracy com estimator 100 : 0.2727272727272727\n",
            "Accuracy com estimator 200 : 0.20454545454545456\n",
            "Accuracy com estimator 500 : 0.22727272727272727\n",
            "Accuracy com estimator 800 : 0.17424242424242425\n",
            "Accuracy GaussianNB: 0.3333333333333333\n",
            "Accuracy MultinominalNB: 0.2727272727272727\n",
            "Accuracy com estimator 100 : 0.3484848484848485\n",
            "Accuracy com estimator 200 : 0.3787878787878788\n",
            "Accuracy com estimator 500 : 0.3560606060606061\n",
            "Accuracy com estimator 800 : 0.3333333333333333\n",
            "Accuracy GaussianNB: 0.24242424242424243\n",
            "Accuracy MultinominalNB: 0.2727272727272727\n",
            "Accuracy com estimator 100 : 0.2196969696969697\n",
            "Accuracy com estimator 200 : 0.22727272727272727\n",
            "Accuracy com estimator 500 : 0.26515151515151514\n",
            "Accuracy com estimator 800 : 0.22727272727272727\n",
            "Accuracy GaussianNB: 0.2196969696969697\n",
            "Accuracy MultinominalNB: 0.2196969696969697\n",
            "Accuracy com estimator 100 : 0.23484848484848486\n",
            "Accuracy com estimator 200 : 0.2196969696969697\n",
            "Accuracy com estimator 500 : 0.26515151515151514\n",
            "Accuracy com estimator 800 : 0.22727272727272727\n",
            "Accuracy GaussianNB: 0.2803030303030303\n",
            "Accuracy MultinominalNB: 0.26515151515151514\n",
            "Accuracy com estimator 100 : 0.3409090909090909\n",
            "Accuracy com estimator 200 : 0.2196969696969697\n",
            "Accuracy com estimator 500 : 0.24242424242424243\n",
            "Accuracy com estimator 800 : 0.22727272727272727\n",
            "Accuracy GaussianNB: 0.19696969696969696\n",
            "Accuracy MultinominalNB: 0.25757575757575757\n",
            "Accuracy com estimator 100 : 0.23484848484848486\n",
            "Accuracy com estimator 200 : 0.23484848484848486\n",
            "Accuracy com estimator 500 : 0.25757575757575757\n",
            "Accuracy com estimator 800 : 0.25\n",
            "Accuracy GaussianNB: 0.26515151515151514\n",
            "Accuracy MultinominalNB: 0.26515151515151514\n",
            "Accuracy com estimator 100 : 0.3409090909090909\n",
            "Accuracy com estimator 200 : 0.25757575757575757\n",
            "Accuracy com estimator 500 : 0.25757575757575757\n",
            "Accuracy com estimator 800 : 0.25757575757575757\n",
            "Accuracy GaussianNB: 0.2727272727272727\n",
            "Accuracy MultinominalNB: 0.2727272727272727\n",
            "Accuracy com estimator 100 : 0.22727272727272727\n",
            "Accuracy com estimator 200 : 0.21212121212121213\n",
            "Accuracy com estimator 500 : 0.25\n",
            "Accuracy com estimator 800 : 0.21212121212121213\n",
            "Accuracy GaussianNB: 0.19696969696969696\n",
            "Accuracy MultinominalNB: 0.19696969696969696\n",
            "Accuracy com estimator 100 : 0.1893939393939394\n",
            "Accuracy com estimator 200 : 0.22727272727272727\n",
            "Accuracy com estimator 500 : 0.25757575757575757\n",
            "Accuracy com estimator 800 : 0.2196969696969697\n",
            "Accuracy GaussianNB: 0.20454545454545456\n",
            "Accuracy MultinominalNB: 0.21212121212121213\n",
            "Accuracy com estimator 100 : 0.25757575757575757\n",
            "Accuracy com estimator 200 : 0.23484848484848486\n",
            "Accuracy com estimator 500 : 0.22727272727272727\n",
            "Accuracy com estimator 800 : 0.21212121212121213\n",
            "Accuracy GaussianNB: 0.2196969696969697\n",
            "Accuracy MultinominalNB: 0.25757575757575757\n",
            "Accuracy com estimator 100 : 0.22727272727272727\n",
            "Accuracy com estimator 200 : 0.21212121212121213\n",
            "Accuracy com estimator 500 : 0.15151515151515152\n",
            "Accuracy com estimator 800 : 0.21212121212121213\n",
            "Accuracy GaussianNB: 0.3333333333333333\n",
            "Accuracy MultinominalNB: 0.3333333333333333\n",
            "Accuracy com estimator 100 : 0.36363636363636365\n",
            "Accuracy com estimator 200 : 0.2878787878787879\n",
            "Accuracy com estimator 500 : 0.38636363636363635\n",
            "Accuracy com estimator 800 : 0.30303030303030304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6NZFbb3FU3x",
        "colab_type": "code",
        "outputId": "a417cc1f-0131-4565-8635-aadb3e717931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "from rlscore.learner import LeaveOneOutRLS\n",
        "from rlscore.measure import ova_accuracy\n",
        "\n",
        "from rlscore.utilities.multiclass import to_one_vs_all\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def load_wine():\n",
        "    np.random.seed(1)\n",
        "    D = np.loadtxt(\"wine.data\", delimiter=\",\")\n",
        "    np.random.shuffle(D)  \n",
        "    X = D[:,1:]\n",
        "    Y = D[:,0].astype(int)\n",
        "    X_train = X[:100]\n",
        "    Y_train = Y[:100]\n",
        "    X_test = X[100:]\n",
        "    Y_test = Y[100:]\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "def print_stats():\n",
        "    X_train, Y_train, X_test, Y_test = load_wine()\n",
        "    print(\"Wine data set characteristics\")\n",
        "    print(\"Training set: {} instances, {} features\" .format(X_train.shape))\n",
        "    print(\"Test set: %d instances, %d features\" %X_test.shape)\n",
        "\n",
        "print_stats()"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-218-ca842c985852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test set: %d instances, %d features\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mprint_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-218-ca842c985852>\u001b[0m in \u001b[0;36mprint_stats\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_wine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wine data set characteristics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training set: {} instances, {} features\"\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-218-ca842c985852>\u001b[0m in \u001b[0;36mload_wine\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_wine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wine.data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: wine.data not found."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD8aVP-e6MxU",
        "colab_type": "text"
      },
      "source": [
        "Naive-Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0kO2Se46R18",
        "colab_type": "code",
        "outputId": "b2e29cdf-f8fd-47b7-82dd-1a73892d252e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "for df in dfL:\n",
        "  X_train,X_test,Y_train,Y_test = train_test_split(df,dfclass, test_size = 0.3, random_state = 900)\n",
        "  \n",
        "  gnb = GaussianNB()\n",
        "\n",
        "  gnb.fit(X_train, Y_train)\n",
        "\n",
        "  y_pred = gnb.predict(X_test)\n",
        "\n",
        "  print('Accuracy GaussianNB: {}'.format(metrics.accuracy_score(Y_test, y_pred)))\n",
        "\n",
        "  gnb = MultinomialNB()\n",
        "\n",
        "  gnb.fit(X_train, Y_train)\n",
        "\n",
        "  y_pred = gnb.predict(X_test)\n",
        "\n",
        "  print('Accuracy MultinominalNB: {}'.format(metrics.accuracy_score(Y_test, y_pred)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy GaussianNB: 0.28125\n",
            "Accuracy MultinominalNB: 0.24759615384615385\n",
            "Accuracy GaussianNB: 0.2548076923076923\n",
            "Accuracy MultinominalNB: 0.27163461538461536\n",
            "Accuracy GaussianNB: 0.2548076923076923\n",
            "Accuracy MultinominalNB: 0.28365384615384615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E288HjBPsocs",
        "colab_type": "text"
      },
      "source": [
        "Random Forrest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLu_i0assqzj",
        "colab_type": "code",
        "outputId": "3496d291-6863-4f70-d943-2206db8cc9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "estimators =[100,200,500,800]\n",
        "\n",
        "for df in dfL:\n",
        "  for n in estimators:\n",
        "    train_features, test_features, train_labels, test_labels = train_test_split(df, dfclass, test_size = 0.25, random_state = 42)\n",
        "    rf = RandomForestClassifier(n_estimators=n)\n",
        "\n",
        "    rf.fit(train_features,train_labels)\n",
        "    predictions = rf.predict(test_features)\n",
        "    print('Accuracy com estimator {} : {}'.format(n,metrics.accuracy_score(test_labels, predictions)))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy com estimator 100 : 0.29394812680115273\n",
            "Accuracy com estimator 200 : 0.29394812680115273\n",
            "Accuracy com estimator 500 : 0.2824207492795389\n",
            "Accuracy com estimator 800 : 0.3285302593659942\n",
            "Accuracy com estimator 100 : 0.24495677233429394\n",
            "Accuracy com estimator 200 : 0.2478386167146974\n",
            "Accuracy com estimator 500 : 0.26512968299711814\n",
            "Accuracy com estimator 800 : 0.24495677233429394\n",
            "Accuracy com estimator 100 : 0.25936599423631124\n",
            "Accuracy com estimator 200 : 0.2737752161383285\n",
            "Accuracy com estimator 500 : 0.2478386167146974\n",
            "Accuracy com estimator 800 : 0.2737752161383285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIo5PLfFtuzk",
        "colab_type": "text"
      },
      "source": [
        "KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFxR8gjgtw3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "neighbors = [1,3,5,10]\n",
        "\n",
        "for df in dfL:\n",
        "  for n in neighbors:\n",
        "    train_features, test_features, train_labels, test_labels = train_test_split(df, dfclass, test_size = 0.25, random_state = 42)\n",
        "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "    neigh.fit(train_features, train_labels)\n",
        "    y_predic = neigh.predict(test_features)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}